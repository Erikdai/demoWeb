import streamlit as st
import sqlite3
import pandas as pd
import requests
from bs4 import BeautifulSoup
from datetime import datetime

st.set_page_config(page_title="æ–°é—»å¿«è®¯", layout="wide")
st.title("ğŸ“° å®æ—¶æ–°é—»å±•ç¤ºï¼ˆæ–°æµªï¼‰")

# âœ… çˆ¬è™«å‡½æ•°
def scrape_news():
    url = 'https://news.sina.com.cn/roll/'
    response = requests.get(url)
    response.encoding = 'utf-8'
    soup = BeautifulSoup(response.text, 'html.parser')

    news_items = []
    for item in soup.select('.news-item'):
        a_tag = item.find('a')
        if a_tag and a_tag.get('href'):
            title = a_tag.get_text(strip=True)
            link = a_tag['href']
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            news_items.append((title, link, timestamp))

    conn = sqlite3.connect("news.db")
    cursor = conn.cursor()
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS news (
            title TEXT,
            link TEXT,
            timestamp TEXT
        )
    ''')
    for news in news_items:
        cursor.execute("SELECT 1 FROM news WHERE title = ? AND link = ?", (news[0], news[1]))
        if not cursor.fetchone():
            cursor.execute("INSERT INTO news (title, link, timestamp) VALUES (?, ?, ?)", news)
    conn.commit()
    conn.close()

# âœ… åŠ ä¸€ä¸ªæ‰‹åŠ¨åˆ·æ–°æŒ‰é’®
if st.button("ğŸ” è·å–æœ€æ–°æ–°é—»"):
    scrape_news()
    st.success("âœ… æ–°é—»å·²æ›´æ–°ï¼Œè¯·ä¸‹æ‹‰æŸ¥çœ‹æœ€æ–°å†…å®¹")
    st.experimental_rerun()  # å¼ºåˆ¶åˆ·æ–°é¡µé¢å±•ç¤ºæ–°æ•°æ®

# âœ… å±•ç¤ºæ–°é—»
conn = sqlite3.connect("news.db")
df = pd.read_sql_query("SELECT * FROM news ORDER BY timestamp DESC LIMIT 20", conn)
conn.close()

st.subheader("æœ€æ–°æ–°é—»ï¼ˆæ¥è‡ªæ–°æµªæ»šåŠ¨ï¼‰")
st.table(df)
st.caption(f"æ•°æ®æ¥æºï¼šhttps://news.sina.com.cn/roll/ æœ€åæ›´æ–°ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
