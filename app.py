import streamlit as st
import sqlite3
import pandas as pd
import requests
from bs4 import BeautifulSoup
from datetime import datetime

st.set_page_config(page_title="æ–°é—»å¿«è®¯", layout="wide")
st.title("ğŸ“° å®æ—¶æ–°é—»å±•ç¤ºï¼ˆæ–°æµªï¼‰")

# åˆå§‹åŒ–åˆ·æ–°çŠ¶æ€
if 'refresh' not in st.session_state:
    st.session_state.refresh = False

# âœ… å¸¦è°ƒè¯•ä¿¡æ¯çš„æ–°æµªæ–°é—»çˆ¬è™«
def scrape_news():
    print("[çˆ¬è™«å¯åŠ¨] æ­£åœ¨æŠ“å–æ–°æµªæ–°é—»...")

    url = 'https://news.sina.com.cn/roll/'
    try:
        response = requests.get(url, timeout=10)
        response.encoding = 'utf-8'
        print(f"[è°ƒè¯•] response status: {response.status_code}")

        soup = BeautifulSoup(response.text, 'html.parser')

        news_items = []
        for item in soup.select('.news-item'):
            a_tag = item.find('a')
            if a_tag and a_tag.get('href'):
                title = a_tag.get_text(strip=True)
                link = a_tag['href']
                timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                print(f"[æ–°é—»] {title} - {link}")  # ğŸ” æ‰“å°æŠ“å–å†…å®¹
                news_items.append((title, link, timestamp))

        print(f"[è°ƒè¯•] å…±æŠ“å–åˆ° {len(news_items)} æ¡æ–°é—»")

        # å†™å…¥æ•°æ®åº“
        conn = sqlite3.connect("news.db")
        cursor = conn.cursor()
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS news (
                title TEXT,
                link TEXT,
                timestamp TEXT
            )
        ''')
        for news in news_items:
            cursor.execute("SELECT 1 FROM news WHERE title = ? AND link = ?", (news[0], news[1]))
            if not cursor.fetchone():
                cursor.execute("INSERT INTO news (title, link, timestamp) VALUES (?, ?, ?)", news)
        conn.commit()
        conn.close()
        print("[æ•°æ®åº“] æ–°é—»æ•°æ®å†™å…¥å®Œæˆ")

    except Exception as e:
        print(f"[é”™è¯¯] æŠ“å–æ–°é—»å¤±è´¥ï¼š{e}")

# ğŸ‘‰ åˆ·æ–°æŒ‰é’®è§¦å‘çˆ¬è™«ï¼ˆä¸ä½¿ç”¨ experimental_rerunï¼‰
if st.button("ğŸ” è·å–æœ€æ–°æ–°é—»"):
    st.session_state.refresh = True

if st.session_state.refresh:
    scrape_news()
    st.success("âœ… æ–°é—»å·²æ›´æ–°")
    st.session_state.refresh = False

# ğŸ“¦ å±•ç¤ºæ•°æ®åº“æ–°é—»
conn = sqlite3.connect("news.db")
df = pd.read_sql_query("SELECT * FROM news ORDER BY timestamp DESC LIMIT 20", conn)
conn.close()

st.subheader("ğŸ“° æœ€æ–°æ–°é—»ï¼ˆæ¥è‡ªæ–°æµªï¼‰")
if df.empty:
    st.warning("âš ï¸ å½“å‰æš‚æ— æ–°é—»æ•°æ®ï¼Œè¯·ç‚¹å‡»ä¸Šæ–¹æŒ‰é’®å°è¯•é‡æ–°æŠ“å–ã€‚")
else:
    st.table(df)

st.caption(f"æ•°æ®æ¥æºï¼šhttps://news.sina.com.cn/roll/ï¼Œæœ€åæ›´æ–°ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
